import os
import time

import torch
import torch.nn as nn
from pytorch_pretrained_bert import BertModel, BertTokenizer
import numpy as np
from importlib import import_module
import argparse
import uvicorn
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

class Config(object):
    """配置参数"""
    def __init__(self, dataset):

        self.class_list = [x.strip() for x in open(
            dataset + '/data/class.txt').readlines()]
        self.save_path = 'THUCNews/saved_dict/bert.ckpt'
        self.device = torch.device('cpu')
        self.require_improvement = 1000  # 若超过1000batch效果还没提升，则提前结束训练
        self.num_classes = len(self.class_list)  # 类别数
        self.num_epochs = 3  # epoch数
        self.batch_size = 128  # mini-batch大小
        self.pad_size = 32  # 每句话处理成的长度(短填长切)
        self.learning_rate = 5e-5  # 学习率
        self.bert_path = './bert_pretrain'
        self.tokenizer = BertTokenizer.from_pretrained(self.bert_path)
        self.hidden_size = 768

    def build_dataset(self, text):
        lin = text.strip()
        pad_size = len(lin)
        token = self.tokenizer.tokenize(lin)
        token = ['[CLS]'] + token
        token_ids = self.tokenizer.convert_tokens_to_ids(token)
        mask = [1] * pad_size
        token_ids = token_ids[:pad_size]
        return torch.tensor([token_ids], dtype=torch.long), torch.tensor([mask])

class Model(nn.Module):
    def __init__(self, config):
        super(Model, self).__init__()
        self.bert = BertModel.from_pretrained(config.bert_path)
        for param in self.bert.parameters():
            param.requires_grad = True
        self.fc = nn.Linear(config.hidden_size, config.num_classes)

    def forward(self, x):
        context = x[0]
        mask = x[1]
        _, pooled = self.bert(context, attention_mask=mask, output_all_encoded_layers=False)
        out = self.fc(pooled)
        return out

def prediction_model(text, config):
    """输入一句问话预测"""
    data = config.build_dataset(text)
    with torch.no_grad():
        outputs = model(data)
    num = torch.argmax(outputs)
    return key[int(num)]

class Item(BaseModel):
    text: str

@app.post("/predict")
async def predict(item: Item):
    print(item.text)
    return {"label": prediction_model(item.text, config)}

if __name__ == '__main__':
    dataset = 'THUCNews' # 数据集
    key = {0: 'finance',
           1: 'realty',
           2: 'stocks',
           3: 'education',
           4: 'science',
           5: 'society',
           6: 'politics',
           7: 'sports',
           8: 'games',
           9: 'entertainment'
           }
    model_name = "bert"  # bert
    x = import_module('models.' + model_name)
    config = x.Config(dataset)
    np.random.seed(1)
    torch.manual_seed(1)
    torch.cuda.manual_seed_all(1)
    torch.backends.cudnn.deterministic = True  # 保证每次结果一样

    start_time = time.time()
    config = Config(dataset)
    model = Model(config).to(config.device)
    model.load_state_dict(torch.load(config.save_path, map_location="cpu"))
    print("Loading data...")
    text = "状元心经：考前一周重点是回顾和整理"
    # prediced= prediction_model(text, config)
    # print(prediced)

    uvicorn.run(app, host="127.0.0.1", port=8000)
